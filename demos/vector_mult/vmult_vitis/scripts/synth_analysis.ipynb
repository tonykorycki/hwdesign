{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7fdbf9f",
   "metadata": {},
   "source": [
    "# Synthesis Analsysis\n",
    "In this notebook, we analyze the synthesis results of the [parameter sweeping](https://sdrangan.github.io/hwdesign/loopopt/paramsweep.html).  As discussed there, we synthesize multiple versions of the vector multiplier with different unroll factors.  Here, we will parse the synthesis results to look at the resource usage for different unrolling factors.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1efec2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2b4ab",
   "metadata": {},
   "source": [
    "## Loading the synthesis output files\n",
    "\n",
    "Follow the steps in the [parameter sweeping](https://sdrangan.github.io/hwdesign/loopopt/paramsweep.html) instructions.  The will create a number of directories:\n",
    "~~~\n",
    "   vmult_vitis\n",
    "   ├── vmult_hls\n",
    "   │   └── sol_uf1\n",
    "   │   └── sol_uf2\n",
    "   │   └── sol_uf4\n",
    "   │   └── sol_uf8\n",
    "~~~\n",
    "where each directory represents the synthesis for different unroll factors 1, 2, 4, and 8.\n",
    "In each of these directories is a **report file** at the location like:\n",
    "~~~bash\n",
    "   sol_uf<n>/syn/report/csynth.xml\n",
    "~~~\n",
    "\n",
    "Feel free to open the file.  You will see it has lots of data on the synthesis results.\n",
    "\n",
    "Since we will parse this data a lot I have written (actually, I got ChatGPT to write it for me)\n",
    "a parser to read these files.  The code is in the `xilinxutils` package which is part of the course.\n",
    "\n",
    "Here, we first use the parser on the output for the synthesis with the unroll factor, `UF = 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c271453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency and Initiation Interval:\n",
      "                                           PipelineII  PipelineDepth\n",
      "vec_mult_Pipeline_input_loop:input_loop             2             14\n",
      "vec_mult_Pipeline_mult_loop:mult_loop               2             13\n",
      "vec_mult_Pipeline_output_loop:output_loop           2              5\n",
      "\n",
      "Resource Usage:\n",
      "                               BRAM_18K  DSP      FF    LUT  URAM\n",
      "vec_mult_Pipeline_input_loop          0    0     979    313     0\n",
      "vec_mult_Pipeline_mult_loop           0    3     472    545     0\n",
      "vec_mult_Pipeline_output_loop         0    0      63    134     0\n",
      "vec_mult                              8    3    2954   2620     0\n",
      "Total                                 8    3    2954   2616     0\n",
      "Available                           280  220  106400  53200     0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import importlib\n",
    "import xilinxutils\n",
    "\n",
    "# Reload to get latest changes during development\n",
    "importlib.reload(xilinxutils)\n",
    "\n",
    "from xilinxutils.csynthparse import CsynthParser\n",
    "import os\n",
    "\n",
    "\n",
    "# Parse the synthesis for UF=1 \n",
    "sol_path = os.path.join(os.getcwd(), '..', 'vmult_hls', 'sol_uf1')\n",
    "parser = CsynthParser(sol_path=sol_path)\n",
    "\n",
    "# Get the latency and initiation interval\n",
    "print('Latency and Initiation Interval:')\n",
    "parser.get_loop_pipeline_info()\n",
    "print(parser.loop_df)\n",
    "\n",
    "# Get the resources\n",
    "print('\\nResource Usage:')\n",
    "parser.get_resources()\n",
    "print(parser.res_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f75c45",
   "metadata": {},
   "source": [
    "We see that we get data for each of the loops.  We will focus on `mult_loop`, the main multiplication loop.  We address pipelining of input and output later.  The trip conunt and total number of cycles  for `n` iterations is:\n",
    "~~~\n",
    "   trip = (n + unroll_factor - 1) // unroll_factor\n",
    "   ncycles = PipelineDepth + PipelineII * (trip - 1)\n",
    "~~~\n",
    "So, `PipelineDepth` is the time for the first iteration and `PipelineII` is the additional time for each other iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c30dda",
   "metadata": {},
   "source": [
    "## Parsing the data for different unroll factors\n",
    "\n",
    "Now let's parse all the solutions to compare the results.  First, we find all the directories with solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ad6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 solution directories:\n",
      "sol_uf1\n",
      "  c:\\Users\\sdran\\Documents\\repos\\hwdesign\\vector_mult\\vmult_vitis\\scripts\\..\\vmult_hls\\sol_uf1\n",
      "sol_uf2\n",
      "  c:\\Users\\sdran\\Documents\\repos\\hwdesign\\vector_mult\\vmult_vitis\\scripts\\..\\vmult_hls\\sol_uf2\n",
      "sol_uf4\n",
      "  c:\\Users\\sdran\\Documents\\repos\\hwdesign\\vector_mult\\vmult_vitis\\scripts\\..\\vmult_hls\\sol_uf4\n",
      "sol_uf8\n",
      "  c:\\Users\\sdran\\Documents\\repos\\hwdesign\\vector_mult\\vmult_vitis\\scripts\\..\\vmult_hls\\sol_uf8\n"
     ]
    }
   ],
   "source": [
    "hls_dir = os.path.join(os.getcwd(), '..', 'vmult_hls')\n",
    "sol_dirs = [d for d in os.listdir(hls_dir) if os.path.isdir(os.path.join(hls_dir, d)) and d.startswith('sol_uf')]\n",
    "sol_dirs.sort()\n",
    "\n",
    "print(f\"Found {len(sol_dirs)} solution directories:\")\n",
    "for d in sol_dirs:\n",
    "    print(f\"  {os.path.join(hls_dir, d)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a81be",
   "metadata": {},
   "source": [
    "Next, we parse each of these directories and get the loop info and resource usage from each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41c21036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing solution: sol_uf1\n",
      "Processing solution: sol_uf2\n",
      "Processing solution: sol_uf4\n",
      "Processing solution: sol_uf8\n"
     ]
    }
   ],
   "source": [
    "res_dfs = {}\n",
    "latency_dfs = {}\n",
    "for sol in sol_dirs:\n",
    "    \n",
    "    sol_path = os.path.join(hls_dir, sol)\n",
    "    base_name = os.path.basename(sol_path)\n",
    "    print(f\"Processing solution: {base_name}\")\n",
    "\n",
    "    # Parse the synthesis report\n",
    "    parser = CsynthParser(sol_path=sol_path)\n",
    "    \n",
    "    # Get resources\n",
    "    parser.get_resources()\n",
    "    res_dfs[base_name] = parser.res_df\n",
    "    \n",
    "    # Get latency and initiation interval\n",
    "    parser.get_loop_pipeline_info()\n",
    "    latency_dfs[base_name] = parser.loop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30e6bb",
   "metadata": {},
   "source": [
    "Now let's look at how the resource usage increases with the unroll factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b940584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           BRAM_18K  DSP      FF    LUT  URAM\n",
      "Solution                                     \n",
      "sol_uf1           8    3    2954   2616     0\n",
      "sol_uf2           8    3    3302   2941     0\n",
      "sol_uf4          14    6    4125   3571     0\n",
      "sol_uf8          26   12    5644   5033     0\n",
      "Available       280  220  106400  53200     0\n"
     ]
    }
   ],
   "source": [
    "res_totals = {}\n",
    "\n",
    "# Get the total resources for each solution from the row 'Total'\n",
    "for sol, df in res_dfs.items():\n",
    "    res_totals[sol] = df.loc['Total']\n",
    "res_totals['Available'] = df.loc['Available']\n",
    "\n",
    "import pandas as pd\n",
    "res_total_df = pd.DataFrame.from_dict(res_totals, orient='index')\n",
    "\n",
    "# Label the index column\n",
    "res_total_df.index.name = 'Solution'\n",
    "\n",
    "print(res_total_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc1daec",
   "metadata": {},
   "source": [
    "Now, let's look at the pipeline info for the multiplication loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f0cbe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          PipelineII  PipelineDepth\n",
      "Solution                           \n",
      "sol_uf1            2             13\n",
      "sol_uf2            2             14\n",
      "sol_uf4            2             14\n",
      "sol_uf8            2             14\n"
     ]
    }
   ],
   "source": [
    "# Get the total resources for each solution from the row 'Total'\n",
    "mult_loop_name = 'vec_mult_Pipeline_mult_loop:mult_loop'\n",
    "loop_data = {}\n",
    "for sol, df in latency_dfs.items():\n",
    "    loop_data[sol] = df.loc[mult_loop_name]\n",
    "\n",
    "loop_df = pd.DataFrame.from_dict(loop_data, orient='index')\n",
    "\n",
    "# Label the index column\n",
    "loop_df.index.name = 'Solution'\n",
    "\n",
    "print(loop_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675e7c4",
   "metadata": {},
   "source": [
    "We see that the pipeline data per trip count is not significantly different from unrolling.  Of course, by unrolling, more is done per trip."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ae747",
   "metadata": {},
   "source": [
    "## BRAM usage\n",
    "\n",
    "It is useful to compare the resource usage for the BRAM. With unrolling we partition the buffer into banks of size:\n",
    "~~~\n",
    "   bank_size = max_size * bit_width / unroll_factor\n",
    "~~~\n",
    "Each bank needs\n",
    "~~~\n",
    "   nbram_per_bank = ceil( bank_size / bram_size)\n",
    "~~~\n",
    "BRAM units.  The banks must go in different BRAM units so they can be addressed indepedenntly.\n",
    "So, the total number of BRAM units is:\n",
    "~~~\n",
    "    bram_exp  = bram_per_bank * nbuf * unroll_factor\n",
    "~~~\n",
    "We can also compute the BRAM utilization as:\n",
    "~~~\n",
    "   bram_util = bank_size / (nbram_per_bank * bram_size)\n",
    "~~~\n",
    "which represents the fraction of the BRAM that we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecdbf4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unroll_Factor  BRAM_Used  BRAM_Expected  BRAM utilization\n",
      "0              1          8              6          0.888889\n",
      "1              2          8              6          0.888889\n",
      "2              4         14             12          0.444444\n",
      "3              8         26             24          0.222222\n"
     ]
    }
   ],
   "source": [
    "# Get the unroll factor from the solution names\n",
    "unroll_factor = []\n",
    "bram_used = []\n",
    "bram_exp = []\n",
    "bram_util = []\n",
    "max_size = 1024\n",
    "bit_width = 32\n",
    "bram_size = 18 * 1024  # in bits\n",
    "nbuf = 3 # One each for a, b, and c\n",
    "\n",
    "for k in res_totals.keys():\n",
    "    if not k.startswith('sol_uf'):\n",
    "        continue \n",
    "\n",
    "    # Get the unroll factor\n",
    "    uf = int(k.split('_uf')[-1])\n",
    "    unroll_factor.append(uf)\n",
    "\n",
    "    # Get the BRAM used\n",
    "    bram_used.append(res_totals[k]['BRAM_18K'])\n",
    "\n",
    "    # Get the expected BRAM usage\n",
    "    bank_size = (max_size * bit_width / uf )\n",
    "    nbram_per_bank = (bank_size + bram_size - 1) // bram_size  # Ceiling division\n",
    "    total_bram = int(nbram_per_bank * uf * nbuf)\n",
    "    bram_exp.append(total_bram)\n",
    "\n",
    "    # Get the BRAM utilization\n",
    "    bram_util.append( bank_size / nbram_per_bank / bram_size)\n",
    "\n",
    "# Create a data frame\n",
    "bram_df = pd.DataFrame({\n",
    "    'Unroll_Factor': unroll_factor,\n",
    "    'BRAM_Used': bram_used,\n",
    "    'BRAM_Expected': bram_exp,\n",
    "    'BRAM utilization': bram_util\n",
    "})\n",
    "\n",
    "print(bram_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff06a3",
   "metadata": {},
   "source": [
    "We see that the BRAM used is slightly higher than expected.  The additional BRAM is due to some BRAM usage for the AXI interface.  Also, we see that the BRAM starts to grow as we bank the data in more memories.  The total memory is constant.  It is just that we have to split the data into small banks and the BRAM units, which have fixed sizes, starts to go under-utilized.  In an ASIC, this would not be such a problem, since we could create arbitrarily small memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaeff92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
